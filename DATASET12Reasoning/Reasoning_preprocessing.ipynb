{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61998122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open ('DATASET10/results.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729e1273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks a string and returns what is inside the \\boxed{} and returns the no_box if there is no \\boxed{}\n",
    "def in_box(string):\n",
    "    try:\n",
    "        return re.search(r'\\\\boxed\\{(.*)\\}', string).group(1)\n",
    "    except:\n",
    "        return 'no_box'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d15c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "boxed=[]\n",
    "for elt in data:\n",
    "    try:\n",
    "        boxed.append(in_box(elt['choices'][0]['message']['content']))\n",
    "    except:\n",
    "        boxed.append('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "615a2a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " 0,\n",
       " '0',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " 'error',\n",
       " 'no_box',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '4',\n",
       " '2',\n",
       " '3',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " 5,\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '2',\n",
       " '5',\n",
       " 'no_box',\n",
       " '3',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " 0,\n",
       " '2',\n",
       " '0',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " 2,\n",
       " 'no_box',\n",
       " '2',\n",
       " '5',\n",
       " '5',\n",
       " '1',\n",
       " '3',\n",
       " '5',\n",
       " '5',\n",
       " 4,\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '2',\n",
       " 5,\n",
       " '2',\n",
       " '2',\n",
       " 0,\n",
       " '0',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " '2',\n",
       " '6',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " 'no_box',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " 'error',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '3',\n",
       " '2',\n",
       " '7',\n",
       " '3',\n",
       " 0,\n",
       " '1',\n",
       " 0,\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '3',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " 0,\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '2',\n",
       " '2',\n",
       " 0,\n",
       " 0,\n",
       " 'error']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newlist=[]\n",
    "for elt in boxed:\n",
    "    newlist.append(box_to_int(elt))\n",
    "newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21474f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def box_to_int(string):\n",
    "    # takes strings like \\\\text{BACKGROUND} \\\\text{FUTURE} \\\\text{BACKGROUND} \\\\text{COMPARES OR CONTRASTS}\n",
    "    # and returns the integer associated with citation dict.\n",
    "    citation_dict={\n",
    "    \"BACKGROUND\":0,\n",
    "    \"USES\":1,\n",
    "    \"COMPARES OR CONTRASTS\":2,\n",
    "    \"MOTIVATION\":3,\n",
    "    \"CONTINUATION\":4,\n",
    "    \"FUTURE\":5\n",
    "    }\n",
    "    for classe in citation_dict.keys():\n",
    "        if classe in string:\n",
    "            return citation_dict[classe]\n",
    "    return string\n",
    "\n",
    "\n",
    "box_to_int(\"\\\\text{BACKGROUND}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f2a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "CORRECT\n",
      "INCORRECT\n",
      "INCORRECT\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "results = []\n",
    "for elt,label in zip(data,list(test['intent'])):\n",
    "        content = elt['choices'][0]['message']['content']\n",
    "        resultat_elt=[-1]\n",
    "        for character in content:\n",
    "            if character.isdigit(): #on met tous les chiffres dans la liste\n",
    "                resultat_elt.append(int(character))\n",
    "        if(label in resultat_elt):\n",
    "            print('CORRECT')\n",
    "        else:\n",
    "            print('INCORRECT')\n",
    "        \n",
    "        results.append(resultat_elt[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97a94d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_results=[]\n",
    "for truc in results:\n",
    "    if int(truc) not in [0,1,2,3,4,5]:\n",
    "        better_results.append(3)\n",
    "    else:\n",
    "        better_results.append(truc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "082177fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(better_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37d9732a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chrif\\Downloads\\synthdata1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"hrithikpiyush/acl-arc\")\n",
    "ds.set_format(\"pandas\")\n",
    "train=ds[\"train\"][:]\n",
    "validation=ds[\"validation\"][:]\n",
    "test=ds[\"test\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5091eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test['intent'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "359c7123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1373ff57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " 0,\n",
       " '0',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " 'error',\n",
       " 'no_box',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '4',\n",
       " '2',\n",
       " '3',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " 5,\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '2',\n",
       " '5',\n",
       " 'no_box',\n",
       " '3',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " 0,\n",
       " '2',\n",
       " '0',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " 2,\n",
       " 'no_box',\n",
       " '2',\n",
       " '5',\n",
       " '5',\n",
       " '1',\n",
       " '3',\n",
       " '5',\n",
       " '5',\n",
       " 4,\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '2',\n",
       " 5,\n",
       " '2',\n",
       " '2',\n",
       " 0,\n",
       " '0',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " '2',\n",
       " '6',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " 'no_box',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " 'error',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '3',\n",
       " '2',\n",
       " '7',\n",
       " '3',\n",
       " 0,\n",
       " '1',\n",
       " 0,\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '3',\n",
       " '3',\n",
       " '1',\n",
       " '3',\n",
       " 0,\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '2',\n",
       " '2',\n",
       " 0,\n",
       " 0,\n",
       " 'error']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6aa26b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listefinale=[]\n",
    "for elt in newlist:\n",
    "    if elt=='error' or elt=='no_box':\n",
    "        listefinale.append(3)\n",
    "    elif elt=='7' or elt=='6':\n",
    "        listefinale.append(5)\n",
    "    else:\n",
    "        listefinale.append(elt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "799f7537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.14      0.24        71\n",
      "           1       0.02      0.04      0.03        26\n",
      "           2       0.14      0.12      0.13        25\n",
      "           3       0.06      0.40      0.11         5\n",
      "           4       0.25      0.14      0.18         7\n",
      "           5       0.19      0.60      0.29         5\n",
      "\n",
      "    accuracy                           0.14       139\n",
      "   macro avg       0.24      0.24      0.16       139\n",
      "weighted avg       0.44      0.14      0.17       139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test['intent'].to_list(), [int(i) for i in listefinale]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752c095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the citation text: \"Our work builds upon the innovative methodology introduced by Smith et al. [14]\"\\n\\n*   **Analysis:** The phrase \"builds upon\" clearly indicates that this research directly extends, develops, or continues the work done by Smith et al. It signifies progression from that specific prior work.\\n*   **Classification:** This matches the definition of **Continuation (4)** - meaning the citing work continues or builds directly on the cited work.\\n\\nTherefore, the citation intent is:\\n**4**'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['5'][-1]['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb952603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( @@CITATION ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .\n",
      "We experiment with four learners commonly employed in language learning : Decision List ( DL ) : We use the DL learner as described in Collins and Singer ( 1999 ) , motivated by its success in the related tasks of word sense disambiguation ( @@CITATION ) and NE classification ( Collins and Singer , 1999 ) .\n",
      "The implementation has been inspired by experience in extracting information from very large corpora ( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging ( @@CITATION ; Clark et al. , 2003 ) .\n",
      "These keywords are potentially useful features because some of them are subclasses of the ACE SCs shown in the left column of Table 1 , while others appear to be correlated with these ACE SCs .2 ( 6 ) INDUCED CLASS : Since the first-sense heuristic used in the previous feature may not be accurate in capturing the SC of an NP , we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. , @@CITATION ) .\n",
      "For instance , @@CITATION , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's favorite fruit ? ''\n",
      "And Collins ( 2000 ) argues for `` keeping track of counts of arbitrary fragments within parse trees '' , which has indeed been carried out in @@CITATION who use exactly the same set of ( all ) tree fragments as proposed in Bod ( 1992 ) .\n",
      "Thus rather than a single training procedure , we can actually partition the examples by predicate , and train a 1For a fixed verb , MI is proportional to @@CITATION 's conditional probability scores for pseudodisambiguation of ( v , n , n â² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) .\n"
     ]
    }
   ],
   "source": [
    "for i in test.iloc:\n",
    "    if(i['intent']==4):\n",
    "        print(i['cleaned_cite_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "415ad0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "juste=[]\n",
    "faux=[]\n",
    "for i,y,z in zip(test.iloc,test['intent'].to_list(), [int(i) for i in results]):\n",
    "    if(y!=z):\n",
    "        faux.append((i['cleaned_cite_text'],y,z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "220c20e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( @@CITATION ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .',\n",
       "  4,\n",
       "  0),\n",
       " ('Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers ( Collins , 1997 ; Charniak , 1997a ; Charniak , 1997b ; Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; @@CITATION ; Tjong Kim Sang and Buchholz , 2000 ) .',\n",
       "  0,\n",
       "  5),\n",
       " ('The advantage of tuning similarity to the application of interest has been shown previously by @@CITATION .',\n",
       "  2,\n",
       "  0),\n",
       " ('Although there are other discussions of the paragraph as a central element of discourse ( e.g. @@CITATION , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .',\n",
       "  2,\n",
       "  9),\n",
       " ('We experiment with four learners commonly employed in language learning : Decision List ( DL ) : We use the DL learner as described in Collins and Singer ( 1999 ) , motivated by its success in the related tasks of word sense disambiguation ( @@CITATION ) and NE classification ( Collins and Singer , 1999 ) .',\n",
       "  4,\n",
       "  1),\n",
       " ('A central technique is to define a joint relation as a noisy-channel model , by composing a joint relation with a cascade of one or more conditional relations as in Fig. 1 ( @@CITATION ; Knight and Graehl , 1998 ) .',\n",
       "  0,\n",
       "  1),\n",
       " ('Our classification framework , directly inspired by @@CITATION , integrates both perspectives , optimizing its labeling of speech segments based on both individual speech-segment classification scores and preferences for groups of speech segments to receive the same label .',\n",
       "  1,\n",
       "  5),\n",
       " ('As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; @@CITATION ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .',\n",
       "  0,\n",
       "  5),\n",
       " ('For instance , @@CITATION report that the SATZ system ( decision tree variant ) was trained on a set of about 800 labeled periods , which corresponds to a corpus of about 16,000 words .',\n",
       "  2,\n",
       "  0),\n",
       " ('One possible direction is to consider linguistically motivated approaches , such as the extraction of syntactic phrase tables as proposed by ( @@CITATION ) .',\n",
       "  5,\n",
       "  4),\n",
       " ('Later works , such as Atallah et al. ( 2001a ) , @@CITATION , Taskiran et al. ( 2006 ) and Topkara et al. ( 2006b ) , further made use of part-ofspeech taggers and electronic dictionaries , such as WordNet and VerbNet , to increase the robustness of the method .',\n",
       "  0,\n",
       "  4),\n",
       " ('A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , @@CITATION , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .',\n",
       "  2,\n",
       "  0),\n",
       " ('The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers ( Ratnaparkhi , 1999 ; Collins , 1999 ; Charniak , 2000 ; @@CITATION ; Bod , 2001 ) .',\n",
       "  2,\n",
       "  0),\n",
       " ('The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines ( @@CITATION ; Clark et al. , 2003 ) .',\n",
       "  0,\n",
       "  1),\n",
       " ('This imbalance foils thresholding strategies , clever as they might be ( Gale & Church , 1991 ; Wu & Xia , 1994 ; @@CITATION ) .',\n",
       "  0,\n",
       "  3),\n",
       " ('For example , our previous work ( @@CITATION ; Nakov and Ng , 2012 ) experimented with various techniques for combining a small bi-text for a resource-poor language ( Indonesian or Spanish , pretending that Spanish is resource-poor ) with a much larger bi-text for a related resource-rich language ( Malay or Portuguese ) ; the target language of all bi-texts was English .',\n",
       "  2,\n",
       "  0),\n",
       " ('@@CITATION replicated the experiment of Rubenstein and Goodenough with the original 65 word pairs translated into German .',\n",
       "  0,\n",
       "  4),\n",
       " (\"One approach to this more general problem , taken by the ` Nitrogen ' generator ( @@CITATIONa ; Langkilde and Knight , 1998b ) , takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model .\",\n",
       "  1,\n",
       "  0),\n",
       " ('13 We also employed sequence-based measures using the ROUGE tool set ( @@CITATION ) , with similar results to those obtained with the word-by-word measures .',\n",
       "  1,\n",
       "  3),\n",
       " ('Second , using continuous distributions allows us to leverage a variety of tools ( e.g. , LDA ) that have been shown to be successful in other fields , such as speech recognition ( @@CITATION ) .',\n",
       "  0,\n",
       "  1),\n",
       " ('The typical solution to the redundancy problem is to group verbs according to their argument realization patterns ( @@CITATION ) , possibly arranged in an inheritance hierarchy .',\n",
       "  2,\n",
       "  0),\n",
       " (\"Later , @@CITATION , 1982 ) proposed a knowledge base in which information about language and the world would be encoded , and he emphasized the need for using `` salience '' in choosing facts from this knowledge base .\",\n",
       "  0,\n",
       "  5),\n",
       " ('ASARES is presented in detail in ( @@CITATION ) .', 1, -1),\n",
       " ('A number of applications have relied on distributional analysis ( @@CITATION ) in order to build classes of semantically related terms .',\n",
       "  0,\n",
       "  1),\n",
       " ('Previous work with MaltParser in Russian , Turkish , and Hindi showed gains with CASE but not with agreement features ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; @@CITATION ) .',\n",
       "  2,\n",
       "  0),\n",
       " ('Consider , for example , the lexical rule in Figure 2 , which encodes a passive lexical rule like the one presented by @@CITATION , 215 ) in terms of the setup of Pollard and Sag ( 1994 , ch .',\n",
       "  2,\n",
       "  7),\n",
       " ('Two applications that , like help-desk , deal with question -- answer pairs are : summarization of e-mail threads ( Dalli , Xia , and Wilks 2004 ; @@CITATION ) , and answer extraction in FAQs ( Frequently Asked Questions ) ( Berger and Mittal 2000 ;',\n",
       "  2,\n",
       "  0),\n",
       " ('Second , in line with the findings of ( @@CITATION ) , the results obtained over the MT-derived corpus are equal to those we achieve over the original RTE3 dataset ( i.e. 63.50 % ) .',\n",
       "  2,\n",
       "  0),\n",
       " ('For example , some similar measures have been used in stylistic experiments in information retrieval on the basis of a robust parser built for information retrieval purposes ( @@CITATION ) .',\n",
       "  0,\n",
       "  1),\n",
       " ('successfully parses , or until a quitting criterion is reached , such as an upper bound on N. Whereas in the loosely coupled system the parser acts as a filter only on completed candidate solutions ( @@CITATION ) , the tightly coupled system allows the parser to discard partial theories that have no way of continuing .',\n",
       "  1,\n",
       "  2),\n",
       " ('@@CITATION substituted the non-terminal X in hierarchical phrase-based model by extended syntactic categories .',\n",
       "  2,\n",
       "  4),\n",
       " ('Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( @@CITATION ; Carter 1987 ; Rich and LuperFoy 1988 ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input .',\n",
       "  0,\n",
       "  3),\n",
       " ('2 The reader is asked to focus on any reasonable size measurement , for example , the maximal horizontal or vertical distance , or some combination of dimensions ( @@CITATION ; also Section 8.1 of the present article ) .',\n",
       "  0,\n",
       "  1),\n",
       " ('The implementation has been inspired by experience in extracting information from very large corpora ( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging ( @@CITATION ; Clark et al. , 2003 ) .',\n",
       "  4,\n",
       "  3),\n",
       " ('Our work is inspired by the latent left-linking model in @@CITATION and the ILP formulation from Chang et al. ( 2011 ) .',\n",
       "  1,\n",
       "  3),\n",
       " (\"The names given to the components vary ; they have been called `` strategic '' and `` tactical '' components ( e.g. , McKeown 1985 ; Thompson 1977 ; Danlos 1987 ) 1 , `` planning '' and `` realization '' ( e.g. , McDonald 1983 ; @@CITATIONa ) , or simply `` what to say '' versus `` how to say it '' ( e.g. , Danlos 1987 ; Reithinger 1990 ) .\",\n",
       "  0,\n",
       "  5),\n",
       " ('Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations ( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; @@CITATION ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring ( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .',\n",
       "  0,\n",
       "  3),\n",
       " ('In order to address these limitations in a practical way , we conducted a small user study where we asked four judges ( graduate students from the Faculty of Information Technology at Monash University ) to assess the responses generated by our system ( @@CITATIONa ) .',\n",
       "  1,\n",
       "  7),\n",
       " ('After the extraction , pruning techniques ( @@CITATION ) can be applied to increase the precision of the extracted paraphrases .',\n",
       "  0,\n",
       "  1),\n",
       " ('In this paper , we extend two classes of model adaptation methods ( i.e. , model interpolation and error-driven learning ) , which have been well studied in statistical language modeling for speech and natural language applications ( e.g. , @@CITATION ; Bellegarda , 2004 ; Gao et al. , 2006 ) , to ranking models for Web search applications .',\n",
       "  0,\n",
       "  4),\n",
       " ('GATE goes beyond earlier systems by using a component-based infrastructure ( @@CITATION ) which the GUI is built on top of .',\n",
       "  0,\n",
       "  4),\n",
       " ('description-level lexical rules ( DLRs ; @@CITATION ) .5 2.2.1 Meta-Level Lexical Rules .',\n",
       "  0,\n",
       "  4),\n",
       " ('In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ; @@CITATION ;',\n",
       "  2,\n",
       "  0),\n",
       " ('These keywords are potentially useful features because some of them are subclasses of the ACE SCs shown in the left column of Table 1 , while others appear to be correlated with these ACE SCs .2 ( 6 ) INDUCED CLASS : Since the first-sense heuristic used in the previous feature may not be accurate in capturing the SC of an NP , we employ a corpusbased method for inducing SCs that is motivated by research in lexical semantics ( e.g. , @@CITATION ) .',\n",
       "  4,\n",
       "  3),\n",
       " ('Nevertheless , the full document text is present in most systems , sometimes as the only feature ( Sugiyama and Okumura , 2007 ) and sometimes in combination with others see for instance ( Chen and Martin , 2007 ; @@CITATION ) - .',\n",
       "  0,\n",
       "  2),\n",
       " ('In a similar vain to @@CITATION and Buchholz et al. ( 1999 ) , the method extends an existing flat shallow-parsing method to handle composite structures .',\n",
       "  5,\n",
       "  2),\n",
       " ('We built a two-stage baseline system , using the perceptron segmentation model from our previous work ( @@CITATION ) and the perceptron POS tagging model from Collins ( 2002 ) .',\n",
       "  3,\n",
       "  1),\n",
       " ('Note that although our current system uses MeSH headings assigned by human indexers , manually assigned terms can be replaced with automatic processing if needed ( @@CITATION ) .',\n",
       "  5,\n",
       "  1),\n",
       " ('Previously ( @@CITATION ) , we assessed the importance of various implicit argument feature groups by conducting feature ablation tests .',\n",
       "  3,\n",
       "  4),\n",
       " (\"For instance , @@CITATION , p. 8 ) says that the sentence `` Reagan thinks bananas , '' which is otherwise strange , is in fact acceptable if it occurs as an answer to the question `` What is Kissinger 's favorite fruit ? ''\",\n",
       "  4,\n",
       "  0),\n",
       " (\"The most detailed evaluation of link tokens to date was performed by ( @@CITATION ) , who trained Brown et al. 's Model 2 on 74 million words of the Canadian Hansards .\",\n",
       "  2,\n",
       "  0),\n",
       " ('Log-linear models have proved successful in a wide variety of applications , and are the inspiration behind one of the best current statistical parsers ( @@CITATION ) .',\n",
       "  2,\n",
       "  0),\n",
       " (\"While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure ( @@CITATION ) :\",\n",
       "  0,\n",
       "  4),\n",
       " (\"A more recent approach , advocated by Rappaport Hovav and Levin ( 1998 ) , describes a basic set of event templates corresponding to Vendler 's event classes ( @@CITATION ) : ( 3 ) a. [ x ACT <MANNER> ] ( activity ) b. [ x <STATE> ] ( state ) c. [ BECOME [ x <STATE> ] ] ( achievement ) d. [ x CAUSE [ BECOME [ x <STATE> ] ] ] ( accomplishment )\",\n",
       "  0,\n",
       "  7),\n",
       " ('@@CITATION combines lexical and dependency mappings to form his generalizations .',\n",
       "  0,\n",
       "  1),\n",
       " ('The reordering models we describe follow our previous work using function word models for translation ( Setiawan et al. , 2007 ; @@CITATION ) .',\n",
       "  3,\n",
       "  4),\n",
       " ('We present experiments on the two standard coreference resolution datasets , ACE-2004 ( NIST , 2004 ) and OntoNotes-5 .0 ( @@CITATION ) .',\n",
       "  1,\n",
       "  6),\n",
       " ('â\\x80¢ Only qualitative observations of the responses were reported ( no formal evaluation was performed ) ( Lapalme and Kosseim 2003 ; @@CITATION ) .',\n",
       "  2,\n",
       "  3),\n",
       " ('And subderivations headed by A1 with external nonterminals only at the leaves , internal nonterminals elsewhere , have probability 1/a1 ( @@CITATION ) .',\n",
       "  0,\n",
       "  1),\n",
       " ('â\\x80¢ Support vector machines for mapping histories to parser actions ( @@CITATION ) .',\n",
       "  1,\n",
       "  0),\n",
       " ('The candidate examples that lead to the most disagreements among the different learners are considered to have the highest TUV ( Cohn , Atlas , and Ladner 1994 ; @@CITATION ) .',\n",
       "  0,\n",
       "  3),\n",
       " ('Subsequently , we extracted the bilingual phrase table from the aligned corpora using the Moses toolkit ( @@CITATION ) .',\n",
       "  1,\n",
       "  7),\n",
       " ('Such systems extract information from some types of syntactic units ( clauses in ( Fillmore and Atkins , 1998 ; Gildea and Jurafsky , 2002 ; @@CITATION ) ; noun phrases in ( Hull and Gomez , 1996 ; Rosario et al. , 2002 ) ) .',\n",
       "  0,\n",
       "  6),\n",
       " (\"The question answering system developed by @@CITATION belongs to the merging category of approaches , where the output of an individual method can be used as input to a different method ( this corresponds to Burke 's cascade sub-category ) .\",\n",
       "  2,\n",
       "  0),\n",
       " ('Discriminant analysis has been employed by researchers in automatic text genre detection ( @@CITATIONb ; Karlgren and Cutting 1994 ) since it offers a simple and robust solution despite the fact that it presupposes normal distributions of the discriminating variables .',\n",
       "  0,\n",
       "  5),\n",
       " ('This model has previously been shown to provide excellent performance on multiple tasks , including prediction of association norms , word substitution errors , semantic inferences , and word similarity ( @@CITATION ; Silberer and Lapata , 2012 ) .',\n",
       "  3,\n",
       "  0),\n",
       " (\"In other words , existing treatments of gradables in GRE fail to take the `` efficiency of language '' into account ( @@CITATION ; see our Section 2 ) .\",\n",
       "  0,\n",
       "  3),\n",
       " ('Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ @@CITATION ; Chiang et al. 2005 ] ) as well as for',\n",
       "  0,\n",
       "  1),\n",
       " ('Following @@CITATION , the IR system ranks documents according to the probability that a document D is relevant given the query Q , P ( D is R IQ ) .',\n",
       "  1,\n",
       "  5),\n",
       " ('We have shown elsewhere ( Jensen and Binot 1988 ; @@CITATIONa , 1987b ) that natural language programs , such as on-line grammars and dictionaries , can be used as referential levels for commonsense reasoning -- for example , to disambiguate PP attachment .',\n",
       "  3,\n",
       "  1),\n",
       " (\"Thus rather than a single training procedure , we can actually partition the examples by predicate , and train a 1For a fixed verb , MI is proportional to @@CITATION 's conditional probability scores for pseudodisambiguation of ( v , n , n â\\x80² ) triples : Pr ( v | n ) = Pr ( v , n ) / Pr ( n ) , which was shown to be a better measure of association than co-occurrence frequency f ( v , n ) .\",\n",
       "  4,\n",
       "  2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915518b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
