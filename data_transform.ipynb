{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers\n",
    "!pip install -U datasets\n",
    "!git clone https://github.com/davidjurgens/citation-function\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1de439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open('api_openrouter.txt', 'r') as f:\n",
    "  API=f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ca2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"hrithikpiyush/acl-arc\")\n",
    "ds.set_format(\"pandas\")\n",
    "train=ds[\"train\"][:]\n",
    "validation=ds[\"validation\"][:]\n",
    "test=ds[\"test\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812854e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 867\n",
      "1 317\n",
      "2 305\n",
      "3 63\n",
      "4 76\n",
      "5 60\n"
     ]
    }
   ],
   "source": [
    "for df in train.groupby('intent'):\n",
    "    print(df[0],len(df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880ebea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste=[]\n",
    "for texte in train['cleaned_cite_text']:\n",
    "  liste.append(texte.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc61eaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you are a Postdoctoral Researcher specializing in Econometrics. Your task is to rewrite the following citation (@@CITATION) whose goal is to provide relevant information for this domain (BACKGROUND). 10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.\n",
      "Imagine you are a Researcher in Industry specializing in Environmental Geography. Your task is to rewrite the following citation (@@CITATION) whose goal is  to use data, methods, etc from the citation. (USES)  10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.\n",
      "Imagine you are a Postdoctoral Researcher specializing in Urban Geography. Your task is to rewrite the following citation (@@CITATION) whose goal is to express similarity/differences to the citation (COMPARES OR CONTRASTS) 10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.\n",
      "Imagine you are a Postdoctoral Researcher specializing in Environmental Policy and Management. Your task is to rewrite the following citation (@@CITATION) whose goal is to illustrate need for data, goals, methods, etc.(MOTIVATION) 10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.\n",
      "Imagine you are a Full Professor specializing in Cosmology. Your task is to rewrite the following citation (@@CITATION) whose goal is to extend the citation's data, methods, etc. (CONTINUATION) 10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.\n",
      "Imagine you are a Associate Professor specializing in Planetary Science. Your task is to rewrite the following citation (@@CITATION) whose goal is to be a potential avenue for future work (FUTURE) 10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "ds = load_dataset(\"hrithikpiyush/acl-arc\")\n",
    "ds.set_format(\"pandas\")\n",
    "train=ds[\"train\"][:]\n",
    "validation=ds[\"validation\"][:]\n",
    "test=ds[\"test\"][:]\n",
    "academic_personas = [\n",
    "    \"PhD Student\",\n",
    "    \"Postdoctoral Researcher\",\n",
    "    \"Assistant Professor\",\n",
    "    \"Associate Professor\",\n",
    "    \"Full Professor\",\n",
    "    \"Researcher in Industry\",\n",
    "]\n",
    "\n",
    "disciplines = [\n",
    "        \"Artificial Intelligence\",\n",
    "        \"Machine Learning\",\n",
    "        \"Computer Vision\",\n",
    "        \"Natural Language Processing\",\n",
    "        \"Cybersecurity\",\n",
    "        \"Distributed Systems\",\n",
    "        \"Algorithms and Complexity\",\n",
    "        \"Databases\",\n",
    "        \"Human-Computer Interaction\",\n",
    "        \"Quantum Computing\",\n",
    "        \"Embedded Systems\",\n",
    "        \"Software Engineering\",\n",
    "        \"Classical Mechanics\",\n",
    "        \"Quantum Mechanics\",\n",
    "        \"Relativity\",\n",
    "        \"Condensed Matter Physics\",\n",
    "        \"Particle Physics\",\n",
    "        \"Nuclear Physics\",\n",
    "        \"Optics and Photonics\",\n",
    "        \"Statistical Mechanics\",\n",
    "        \"Astrophysics\",\n",
    "        \"Acoustics\",\n",
    "        \"Plasma Physics\",\n",
    "        \"Biophysics\",\n",
    "        \"Algebra\",\n",
    "        \"Real Analysis\",\n",
    "        \"Complex Analysis\",\n",
    "        \"Topology\",\n",
    "        \"Differential Geometry\",\n",
    "        \"Number Theory\",\n",
    "        \"Probability Theory\",\n",
    "        \"Statistics\",\n",
    "        \"Numerical Analysis\",\n",
    "        \"Optimization\",\n",
    "        \"Mathematical Logic\",\n",
    "        \"Applied Mathematics\",\n",
    "        \"Organic Chemistry\",\n",
    "        \"Inorganic Chemistry\",\n",
    "        \"Physical Chemistry\",\n",
    "        \"Analytical Chemistry\",\n",
    "        \"Biochemistry\",\n",
    "        \"Materials Chemistry\",\n",
    "        \"Theoretical and Computational Chemistry\",\n",
    "        \"Environmental Chemistry\",\n",
    "        \"Polymer Chemistry\",\n",
    "        \"Surface Chemistry\",\n",
    "        \"Molecular Biology\",\n",
    "        \"Cell Biology\",\n",
    "        \"Genetics and Genomics\",\n",
    "        \"Microbiology\",\n",
    "        \"Neurobiology\",\n",
    "        \"Ecology\",\n",
    "        \"Evolutionary Biology\",\n",
    "        \"Developmental Biology\",\n",
    "        \"Physiology\",\n",
    "        \"Botany\",\n",
    "        \"Zoology\",\n",
    "        \"Systems Biology\",\n",
    "        \"Internal Medicine\",\n",
    "        \"Surgery\",\n",
    "        \"Pediatrics\",\n",
    "        \"Psychiatry\",\n",
    "        \"Cardiology\",\n",
    "        \"Oncology\",\n",
    "        \"Neurology\",\n",
    "        \"Radiology\",\n",
    "        \"Anesthesiology\",\n",
    "        \"Emergency Medicine\",\n",
    "        \"Primary Care\",\n",
    "        \"Public Health and Epidemiology\",\n",
    "        \"Mechanical Engineering\",\n",
    "        \"Electrical Engineering\",\n",
    "        \"Civil Engineering\",\n",
    "        \"Chemical Engineering\",\n",
    "        \"Aerospace Engineering\",\n",
    "        \"Biomedical Engineering\",\n",
    "        \"Environmental Engineering\",\n",
    "        \"Materials Engineering\",\n",
    "        \"Industrial Engineering\",\n",
    "        \"Computer Engineering\",\n",
    "        \"Robotics\",\n",
    "        \"Systems Engineering\",\n",
    "        \"Microeconomics\",\n",
    "        \"Macroeconomics\",\n",
    "        \"Econometrics\",\n",
    "        \"Behavioral Economics\",\n",
    "        \"Development Economics\",\n",
    "        \"International Economics\",\n",
    "        \"Public Economics\",\n",
    "        \"Environmental Economics\",\n",
    "        \"Health Economics\",\n",
    "        \"Labor Economics\",\n",
    "        \"Financial Economics\",\n",
    "        \"Cognitive Psychology\",\n",
    "        \"Developmental Psychology\",\n",
    "        \"Social Psychology\",\n",
    "        \"Clinical Psychology\",\n",
    "        \"Neuropsychology\",\n",
    "        \"Industrial-Organizational Psychology\",\n",
    "        \"Health Psychology\",\n",
    "        \"Personality Psychology\",\n",
    "        \"Psychometrics\",\n",
    "        \"Educational Psychology\",\n",
    "        \"Sociological Theory\",\n",
    "        \"Social Stratification\",\n",
    "        \"Cultural Sociology\",\n",
    "        \"Sociology of Education\",\n",
    "        \"Urban Sociology\",\n",
    "        \"Medical Sociology\",\n",
    "        \"Economic Sociology\",\n",
    "        \"Political Sociology\",\n",
    "        \"Family Sociology\",\n",
    "        \"Quantitative Methods\",\n",
    "        \"Qualitative Methods\",\n",
    "        \"Mineralogy and Petrology\",\n",
    "        \"Structural Geology\",\n",
    "        \"Sedimentology\",\n",
    "        \"Stratigraphy\",\n",
    "        \"Paleontology\",\n",
    "        \"Geomorphology\",\n",
    "        \"Geochemistry\",\n",
    "        \"Geophysics\",\n",
    "        \"Hydrogeology\",\n",
    "        \"Environmental Geology\",\n",
    "        \"Remote Sensing in Geology\",\n",
    "        \"Observational Astronomy\",\n",
    "        \"Theoretical Astronomy\",\n",
    "        \"Planetary Science\",\n",
    "        \"Stellar Astrophysics\",\n",
    "        \"Extragalactic Astronomy\",\n",
    "        \"Cosmology\",\n",
    "        \"Astrochemistry\",\n",
    "        \"High-energy Astrophysics\",\n",
    "        \"Radio Astronomy\",\n",
    "        \"Infrared and Optical Astronomy\",\n",
    "        \"Climate Science\",\n",
    "        \"Conservation Biology\",\n",
    "        \"Environmental Chemistry\",\n",
    "        \"Ecology\",\n",
    "        \"Environmental Policy and Management\",\n",
    "        \"Hydrology\",\n",
    "        \"Soil Science\",\n",
    "        \"Atmospheric Science\",\n",
    "        \"Sustainability Science\",\n",
    "        \"Environmental Impact Assessment\",\n",
    "        \"Comparative Politics\",\n",
    "        \"International Relations\",\n",
    "        \"Political Theory\",\n",
    "        \"Public Policy\",\n",
    "        \"Political Economy\",\n",
    "        \"Electoral Studies\",\n",
    "        \"Political Behavior\",\n",
    "        \"Public Administration\",\n",
    "        \"Security Studies\",\n",
    "        \"Governance and Institutions\",\n",
    "        \"Ancient History\",\n",
    "        \"Medieval History\",\n",
    "        \"Early Modern History\",\n",
    "        \"Modern History\",\n",
    "        \"Economic History\",\n",
    "        \"Social and Cultural History\",\n",
    "        \"Military History\",\n",
    "        \"History of Science and Technology\",\n",
    "        \"Oral History\",\n",
    "        \"Public History\",\n",
    "        \"Phonetics\",\n",
    "        \"Phonology\",\n",
    "        \"Morphology\",\n",
    "        \"Syntax\",\n",
    "        \"Semantics\",\n",
    "        \"Pragmatics\",\n",
    "        \"Sociolinguistics\",\n",
    "        \"Psycholinguistics\",\n",
    "        \"Computational Linguistics\",\n",
    "        \"Historical Linguistics\",\n",
    "        \"Field Linguistics\",\n",
    "        \"Cultural Anthropology\",\n",
    "        \"Biological Anthropology\",\n",
    "        \"Archaeology\",\n",
    "        \"Linguistic Anthropology\",\n",
    "        \"Medical Anthropology\",\n",
    "        \"Economic Anthropology\",\n",
    "        \"Urban Anthropology\",\n",
    "        \"Ethnography\",\n",
    "        \"Visual Anthropology\",\n",
    "        \"Anthropology of Religion\",\n",
    "        \"Metaphysics\",\n",
    "        \"Epistemology\",\n",
    "        \"Ethics\",\n",
    "        \"Political Philosophy\",\n",
    "        \"Philosophy of Mind\",\n",
    "        \"Philosophy of Science\",\n",
    "        \"Logic\",\n",
    "        \"Aesthetics\",\n",
    "        \"Philosophy of Language\",\n",
    "        \"History of Philosophy\",\n",
    "        \"Physical Geography\",\n",
    "        \"Human Geography\",\n",
    "        \"Geographic Information Systems (GIS)\",\n",
    "        \"Urban Geography\",\n",
    "        \"Economic Geography\",\n",
    "        \"Political Geography\",\n",
    "        \"Cultural Geography\",\n",
    "        \"Environmental Geography\",\n",
    "        \"Cartography\",\n",
    "        \"Remote Sensing\",\n",
    "        \"Ancient Art\",\n",
    "        \"Medieval Art\",\n",
    "        \"Renaissance Art\",\n",
    "        \"Baroque and Rococo\",\n",
    "        \"Modern Art\",\n",
    "        \"Contemporary Art\",\n",
    "        \"Non-Western Art Histories\",\n",
    "        \"Iconography\",\n",
    "        \"Museum Studies\",\n",
    "        \"Conservation and Restoration\",\n",
    "        \"Harmony\",\n",
    "        \"Counterpoint\",\n",
    "        \"Form and Analysis\",\n",
    "        \"Aural Skills\",\n",
    "        \"Tonal Theory\",\n",
    "        \"Atonal and Serial Techniques\",\n",
    "        \"Ethnomusicology\",\n",
    "        \"Music Cognition\",\n",
    "        \"Music Notation and Editorial Practices\",\n",
    "        \"Contemporary Music Theory\",\n",
    "        \"Comparative Literature\",\n",
    "        \"Literary Theory and Criticism\",\n",
    "        \"Medieval and Early Modern Literature\",\n",
    "        \"Modern and Contemporary Literature\",\n",
    "        \"Postcolonial Literature\",\n",
    "        \"Genre Studies\",\n",
    "        \"Narrative Theory\",\n",
    "        \"Digital Humanities and Literature\",\n",
    "        \"Translation Studies\",\n",
    "        \"Children's and Young Adult Literature\",\n",
    "        \"Curriculum and Instruction\",\n",
    "        \"Educational Psychology\",\n",
    "        \"Assessment and Evaluation\",\n",
    "        \"Educational Policy\",\n",
    "        \"Special Education\",\n",
    "        \"Early Childhood Education\",\n",
    "        \"Higher Education Studies\",\n",
    "        \"Technology in Education\",\n",
    "        \"Adult and Continuing Education\",\n",
    "        \"Multicultural Education\"\n",
    "    ]\n",
    "\n",
    "disciplines_1 = [\n",
    "    \"Computer Science\",\n",
    "    \"Physics\",\n",
    "    \"Mathematics\",\n",
    "    \"Chemistry\",\n",
    "    \"Biology\",\n",
    "    \"Medicine\",\n",
    "    \"Engineering\",\n",
    "    \"Economics\",\n",
    "    \"Psychology\",\n",
    "    \"Sociology\",\n",
    "    \"Geology\",\n",
    "    \"Astronomy\",\n",
    "    \"Environmental Science\",\n",
    "    \"Political Science\",\n",
    "    \"History\",\n",
    "    \"Linguistics\",\n",
    "    \"Anthropology\",\n",
    "    \"Philosophy\",\n",
    "    \"Geography\",\n",
    "    \"Art History\",\n",
    "    \"Music Theory\",\n",
    "    \"Literature\",\n",
    "    \"Education\"\n",
    "]\n",
    "\n",
    "place_sentence=['beginning', 'middle', 'end']\n",
    "citation_intent=['BACKGROUND','USES' ,'COMPARES OR CONTRASTS' ,'MOTIVATION', 'CONTINUATION', 'FUTURE' ]\n",
    "prompt_intent={\n",
    "    \"BACKGROUND\":\"to provide relevant information for this domain (BACKGROUND).\",\n",
    "    \"MOTIVATION\":\"to illustrate need for data, goals, methods, etc.(MOTIVATION)\",\n",
    "    \"USES\":\" to use data, methods, etc from the citation. (USES) \",  \n",
    "    \"CONTINUATION\":\"to extend the citation's data, methods, etc. (CONTINUATION)\",\n",
    "    \"COMPARES OR CONTRASTS\":\"to express similarity/differences to the citation (COMPARES OR CONTRASTS)\",\n",
    "    \"FUTURE\": \"to be a potential avenue for future work (FUTURE)\"\n",
    "}\n",
    "\n",
    "citation_dict={\n",
    "    0:\"BACKGROUND\",\n",
    "    1:\"USES\",\n",
    "    2:\"COMPARES OR CONTRASTS\",\n",
    "    3:\"MOTIVATION\",\n",
    "    4:\"CONTINUATION\",\n",
    "    5:\"FUTURE\"\n",
    "}\n",
    "import random\n",
    "\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"hrithikpiyush/acl-arc\")\n",
    "ds.set_format(\"pandas\")\n",
    "train=ds[\"train\"][:]\n",
    "validation=ds[\"validation\"][:]\n",
    "test=ds[\"test\"][:]\n",
    "\n",
    "\n",
    "\n",
    "def generate_researcher_prompt(numero_classe,academic_personas=academic_personas, disciplines=disciplines, citation_intent=citation_intent,prompt_intent=prompt_intent):\n",
    "  persona = random.choice(academic_personas)\n",
    "  discipline = random.choice(disciplines)\n",
    "  intent=citation_dict[numero_classe]\n",
    "  intent=prompt_intent[intent]\n",
    "  prompt = f\"Imagine you are a {persona} specializing in {discipline}. Your task is to rewrite the following citation (@@CITATION) whose goal is {intent} 10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.\"\n",
    "  return prompt\n",
    "\n",
    "# Example usage:\n",
    "print(generate_researcher_prompt(numero_classe=0))\n",
    "print(generate_researcher_prompt(numero_classe=1))\n",
    "print(generate_researcher_prompt(numero_classe=2))\n",
    "print(generate_researcher_prompt(numero_classe=3))\n",
    "print(generate_researcher_prompt(numero_classe=4))\n",
    "print(generate_researcher_prompt(numero_classe=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3679adcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imagine you are a Associate Professor specializing in Cultural Anthropology. Your task is to rewrite the following citation (@@CITATION) whose goal is to provide relevant information for this domain (BACKGROUND). 10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_researcher_prompt(numero_classe=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a30e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt,label in zip(train['cleaned_cite_text'],train['intent']):\n",
    "    PROMPT=(generate_researcher_prompt(label)+' here is the citation:',txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94299fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_string(id):\n",
    "  try:\n",
    "    with open('/content/citation-function/data/adjudicated-and-supplemental/'+id+'-parscit.130908.xml.txt', 'r') as f:\n",
    "      file_contents = f.read()\n",
    "  except FileNotFoundError:\n",
    "    with open('/content/citation-function/data/adjudicated-and-supplemental/'+id+'.xml.txt', 'r') as f:\n",
    "      file_contents = f.read()\n",
    "\n",
    "\n",
    "  return file_contents\n",
    "\n",
    "def string_few_shots(nb_of_citations):\n",
    "  output_string = \"\"\n",
    "  for j in range(0,6): #pour chaque classe\n",
    "    compteur=nb_of_citations\n",
    "    for count,letuple in enumerate (zip(train['intent'],train['cleaned_cite_text'],train['section_name'])): #on parcourt toutes les citations\n",
    "      if(letuple[0] == j): #si elle a la bonne classe\n",
    "        #output_string += f\"CLASS: {citation_dict[j]}  SECTION NAME:{letuple[2]} CITATION: {letuple[1]}\\n\" #on l'ajoute à la string\n",
    "        output_string += f\"CLASS: {citation_dict[j]} CITATION: {letuple[1]}\\n\" #on l'ajoute à la string\n",
    "\n",
    "        compteur-=1 # et on décrémente\n",
    "        if(compteur==0): #si on arrive à zéro on passe à la classe d'après\n",
    "          break\n",
    "  return output_string\n",
    "\n",
    "\n",
    "\n",
    "def string_few_shots_2(nb_of_citations,class_number):\n",
    "  output_string = \"\"\n",
    "  j=class_number\n",
    "  compteur=nb_of_citations\n",
    "  for count,letuple in enumerate (zip(train['intent'],train['cleaned_cite_text'],train['section_name'])): #on parcourt toutes les citations\n",
    "    if(letuple[0] == j): #si elle a la bonne classe\n",
    "      #output_string += f\"CLASS: {citation_dict[j]}  SECTION NAME:{letuple[2]} CITATION: {letuple[1]}\\n\" #on l'ajoute à la string\n",
    "      output_string += f\"CLASS: {citation_dict[j]} CITATION: {letuple[1]}\\n\" #on l'ajoute à la string\n",
    "\n",
    "      compteur-=1 # et on décrémente\n",
    "      if(compteur==0): #si on arrive à zéro on passe à la classe d'après\n",
    "        break\n",
    "  return output_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d57c964e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Imagine you are a PhD Student specializing in Modern and Contemporary Literature. Your task is to rewrite the following citation (@@CITATION) whose goal is to provide relevant information for this domain (BACKGROUND). 10 times in different ways, the said citations (@@CITATION) should keep the same citation intent but change the scientific domain. Each citation should be different but keep the same spirit.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_researcher_prompt(numero_classe=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "046364ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "5\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "5\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "1\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "5\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "4\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "3\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "5\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "3\n",
      "0\n",
      "5\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "5\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "5\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "5\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "3\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "5\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "5\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "3\n",
      "3\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "1\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "5\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "5\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "5\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n",
      "0\n",
      "2\n",
      "4\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "4\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "2\n",
      "4\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "4\n",
      "1\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "5\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "3\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "5\n",
      "4\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "2\n",
      "0\n",
      "0\n",
      "2\n",
      "5\n",
      "2\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "0\n",
      "0\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "4\n",
      "2\n",
      "2\n",
      "0\n",
      "1\n",
      "1\n",
      "3\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "0\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for txt,label in zip(train['cleaned_cite_text'],train['intent']):\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dddad65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_liste=[0,0,0,0,0,0]\n",
    "liste_textes=[]\n",
    "for txt,label in zip(train['cleaned_cite_text'],train['intent']):\n",
    "    if label_liste[label]<10:\n",
    "        label_liste[label]+=1\n",
    "        liste_textes.append((txt,label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86d7aa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers ( @@CITATION ; Charniak , 1997a ; Charniak , 1997b ; Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 ) .',\n",
       " 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liste_textes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "les_rez=[]\n",
    "dico_rez={0:[],1:[],2:[],3:[],4:[],5:[]}\n",
    "\n",
    "url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "i=0\n",
    "\n",
    "headers = {\n",
    "  \"Authorization\": f\"Bearer {API}\",\n",
    "  \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "for binome in liste_textes:\n",
    "    txt=binome[0]\n",
    "    label=binome[1]\n",
    "    i+=1\n",
    "    for j in range(0,10):\n",
    "      print(i,j)\n",
    "      PROMPT=(generate_researcher_prompt(numero_classe=label)+'\\n here is the CITATION'+txt)  \n",
    "      #try:\n",
    "      payload = {\n",
    "          \"model\": \"deepseek/deepseek-chat-v3-0324\",\n",
    "        \"messages\": [\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": PROMPT\n",
    "          }\n",
    "        ]\n",
    "          ,\n",
    "      #   \"provider\": {\n",
    "      #     \"allow_fallbacks\": True,\n",
    "      #     \"quantizations\": [\n",
    "      #       \"fp8\"\n",
    "      #     ]\n",
    "      # },\n",
    "          \"reasoning\": {\n",
    "\n",
    "        \"enabled\": True  # Use high reasoning effort\n",
    "\n",
    "    }\n",
    "      }\n",
    "      response = requests.post(url, headers=headers, json=payload)\n",
    "      les_rez.append(response.json())\n",
    "      dico_rez[label].append(response.json())\n",
    "    #except:\n",
    "      #  print(\"error\")\n",
    "      #  continue\n",
    "      print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b38f4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,6):\n",
    "    for elt in dico_rez[i]:\n",
    "        with open(f'DATASET8/results_openrouter_intent_{i}.txt', 'a',encoding='utf-8') as f:\n",
    "            f.write(elt['choices'][0]['message']['content'] + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fabde5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
